# python ì½”ë“œë¡œ LLaVA ì‹¤í–‰í•˜ê¸°
import torch, textwrap, re # ë¼ë°” ë‹µë³€ ì¤„ë°”ê¿ˆ
from transformers import AutoProcessor, LlavaForConditionalGeneration, BitsAndBytesConfig
from PIL import Image
from googletrans import Translator # ë²ˆì—­ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os

# LLaVA ëª¨ë¸ ë¡œë“œë¥¼ ë§¤ë²ˆ í•˜ì§€ ì•Šë„ë¡ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸ (í•œ ë²ˆë§Œ ë¡œë“œ)
_model = None
_processor = None
_device = None

REF_DIR = "./reference_images" # ICL ê¸°ë²• í”„ë¡¬í”„íŠ¸ì— ë“¤ì–´ê°ˆ ì˜ˆì‹œ ì‚¬ì§„ë“¤

# ì†ìƒ ìœ í˜•
defect_type_choice = {
    "Concrete Crack" : "ì½˜í¬ë¦¬íŠ¸ ê· ì—´",
    "Paing Damage" : "ë„ì¥ ì†ìƒ",
    "Rebar Exposure" : "ì² ê·¼ ë…¸ì¶œ"
}

# ìœ„í—˜ë„
urgency_choice = {
    "High" : "ë†’ìŒ",
    "Medium" : "ë³´í†µ",
    "Low" : "ë‚®ìŒ"
}

def load_llava_model():
    global _model, _processor, _device
    if _model is not None and _processor is not None:
        return _model, _processor, _device

    # 1. ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ì¤€ë¹„
    model_id = "llava-hf/llava-1.5-7b-hf"
    revision = "a272c74"

    # # 4-bit ì–‘ìí™” ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ í•„ìˆ˜!)-> cuda ì „ìš©
    # quantization_config = BitsAndBytesConfig(
    #     load_in_4bit=True,
    #     bnb_4bit_compute_dtype=torch.float16
    # )

    
    if torch.backends.mps.is_available(): # ë§¥ë¶ gpu
        _device = "mps"
    elif torch.cuda.is_available(): # ì„œë²„ gpu
        _device = "cuda"
    else:
        _device = "cpu"
    
    # ëª¨ë¸ ë¡œë“œ
    print("--- LLaVA ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘... ---")
    _model = LlavaForConditionalGeneration.from_pretrained(
        model_id,
        revision=revision,
        torch_dtype=torch.float16,
        device_map="auto"
    ).to(_device)

    # Processor: fast â†’ ì‹¤íŒ¨ ì‹œ slow
    try:
        _processor = AutoProcessor.from_pretrained(model_id, revision=revision)
    except Exception as e:
       print("Processor load failed:", e)
       raise
    
    print("âœ… LLaVA ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    return _model, _processor, _device

def _as_str(m): # re.Match ê°ì²´ strë¡œ ë³€í™˜
    return m.group(1).strip() if isinstance(m, re.Match) else (m.strip() if isinstance(m, str) else "")


# ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•œ ë¼ë°” ë‹µë³€
def run_llava(image_path: str, question: str):
    """
    ë””ìŠ¤ì½”ë“œ ì±—ë´‡ì—ì„œ í˜¸ì¶œìš©:
    image_path: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    question: ë²„íŠ¼ìœ¼ë¡œ ë°›ì€ í•œêµ­ì–´ ì§ˆë¬¸
    """

    model, processor, device = load_llava_model()

    # 2. ì´ë¯¸ì§€ì™€ í”„ë¡¬í”„íŠ¸ ì…ë ¥ë°›ê¸°
    # ./images/sample.jpg
    
    image_path = image_path if question else "."+image_path
    image = Image.open(image_path)

    # LLaVA ì¶”ê°€ ì§ˆë¬¸ ëª©ë¡
    llava_questions = {
        "ì´ë¯¸ì§€ì— ë‚˜íƒ€ë‚œ ì†ìƒì— ëŒ€í•´ ë¶„ì„ ìš”ì•½í•´ì£¼ì„¸ìš”": textwrap.dedent("""You are an AI assistant analyzing a potential building defect from a drone image for a preliminary assessment.
                                                Your analysis is NOT a substitute for a professional engineering inspection.
                                                Provide a concise yet informative summary of the defectâ€™s visible characteristics and overall condition.
                                                Describe the shape, size, and color or texture differences compared to the surrounding area.
                                                Then, include a short analytical summary describing how severe or extensive the defect appears visually, as if giving a quick inspection report."""),
        "ì´ ì†ìƒì˜ ìœ„í—˜ë„ë¥¼ 1~10 ë‹¨ê³„ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”": textwrap.dedent("""You are an AI assistant analyzing a potential building defect from a drone image for a preliminary assessment.
                                                Your analysis is NOT a substitute for a professional engineering inspection.
                                                Evaluate the damage risk level on a scale of 1 to 10. Answer in the following format: \"It is XX points. {Write the reason in less than three sentences.}\"""")
    }

    user_text =  llava_questions.get(question) if question else (prompt_start).strip()
    messages = [{
        "role": "user",
        "content": [
            {"type": "image"},
            {"type": "text", "text": user_text},
        ],
    }]

    # ëª¨ë¸ìš© í…œí”Œë¦¿ ë¬¸ìì—´ ìƒì„±
    prompt_for_model = processor.apply_chat_template(
        messages, add_generation_prompt=True, tokenize=False
    )

    # 3. ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
    processor.patch_size = model.config.vision_config.patch_size
    processor.vision_feature_select_strategy = model.config.vision_feature_select_strategy
    inputs = processor(images=image, text=prompt_for_model, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}
    model.to(device)

    generate_ids = model.generate(**inputs, max_new_tokens=1000) # max_new_tokensë¡œ ë‹µë³€ ê¸¸ì´ ì¡°ì ˆ
    english_result_full = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]

    # 4. ê²°ê³¼ ì¶œë ¥
    # í”„ë¡¬í”„íŠ¸ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ ë‹µë³€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
    english_result = english_result_full.split("ASSISTANT:")[-1].strip()

    translator = Translator()

    korean_result = translator.translate(english_result, src='en', dest='ko').text
    formatted_korean = re.sub(r'(?<=[ê°€-í£\w][ë‹¤ìš”í•¨ì„]\.)+', '\n', korean_result).strip()
    # 'ë‹¤.', 'ìš”.' ë“±ìœ¼ë¡œ ëë‚˜ê³  ê³µë°±ì´ ì´ì–´ì§ˆ ë•Œ
    return formatted_korean
    
# icl_llava(ì²˜ìŒ ì‚¬ì§„ ë¶„ì„ ì‹œ ì‚¬ìš©)
def run_icl_llava(target_image_path, examples, question, options, mode):
    """
    In-Context Learningì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    :param target_image_path: ë¶„ì„í•  ëŒ€ìƒ ì´ë¯¸ì§€ ê²½ë¡œ
    :param examples: [(ì´ë¯¸ì§€ê²½ë¡œ, ì •ë‹µë¼ë²¨), ...] í˜•íƒœì˜ íŠœí”Œ ë¦¬ìŠ¤íŠ¸
    :param question: ëª¨ë¸ì—ê²Œ ë˜ì§ˆ ì§ˆë¬¸
    :param options: ëª¨ë¸ì´ ì„ íƒí•´ì•¼ í•  ë‹µë³€ ëª©ë¡ (ì˜ˆ: ['Low', 'Medium', 'High'])
    :return: ëª¨ë¸ì˜ í…ìŠ¤íŠ¸ ë‹µë³€
    """
    model, processor, device = load_llava_model()

    # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ference images + target image)
    image_list=[]

    # í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ êµ¬ì„± (chat template í˜•ì‹)
    # LLaVAëŠ” <image> í† í° ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ ë§¤í•‘í•¨
    prompt_text = "You are an AI assistant analyzing a potential building defect from a drone image for a preliminary assessment.Your analysis is NOT a substitute for a professional engineering inspection.Analyze the image carefully and provide the following information in a structured format."

    if mode: prompt_text += "Your task is to classify the final target image based on visual similarity to the provided examples.\n"
    
    for path, label in examples:
        if not os.path.exists(path):
            print(f"ê²½ê³ : ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.: {path}")
            continue

        img = Image.open(path).convert("RGB")
        image_list.append(img)
        prompt_text += f"Example: <image>\nAnswer: {label}\n"

    target_img = Image.open(target_image_path).convert("RGB")
    image_list.append(target_img)
    prompt_text += f"Target: <image>\nQuestion: {question}\nChoose one from: {options}\nAnswer:"

    messages = [
        {"role":"user",
         "content":[
            {"type": "text", "text": prompt_text}
        ]}
    ]

    # apply_chat_templateì€ í…ìŠ¤íŠ¸ í¬ë§·íŒ…ì„ ë„ì™€ì¤ë‹ˆë‹¤.
    # í•˜ì§€ë§Œ LLaVA 1.5 HF êµ¬í˜„ì²´ëŠ” í…ìŠ¤íŠ¸ ë‚´ <image> ê°œìˆ˜ì™€ image_list ê¸¸ì´ê°€ ê°™ì•„ì•¼ í•¨.
    text_prompt = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)

    inputs = processor(text=text_prompt, images=image_list, return_tensors="pt").to(device)

    with torch.inference_mode():
        generate_ids = model.generate(**inputs, max_new_tokens=20) # ë‹µë³€ì€ ì§§ê²Œ
    
    output = processor.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]

    # ë‹µë³€ ì¶”ì¶œ ("ASSISTANT:" ì´í›„)
    answer = output.split("ASSISTANT:")[-1].strip()
    print(f"answer: {answer}\n")
    return answer

# ì†ìƒ ì´ë¯¸ì§€ì— ëŒ€í•œ ì²« ì†ìƒ ì•Œë¦¼
def analyze_defect_basic(target_image_filename):
    """
    step 1: ìœ í˜•ë¶„ë¥˜ -> step 2: ê·¸ì— ë§ëŠ” ìœ„í—˜ë„ íŒë‹¨
    """

    target_path = "."+target_image_filename

    if not os.path.exists(target_path):
        return "ì´ë¯¸ì§€ ì—†ìŒ", "ì´ë¯¸ì§€ ì—†ìŒ"
    
    print(f"\nğŸš€ [ë¶„ì„ ì‹œì‘] {target_image_filename}")

    # ------step 1 : ì†ìƒ ìœ í˜• ë¶„ë¥˜------
    print(">>> step 1. ì†ìƒ ìœ í˜• ë¶„ë¥˜ ì¤‘...")

    # ìœ í˜•ë³„ ì°¸ì¡°í•  ëŒ€í‘œ ì´ë¯¸ì§€
    type_examples = [
        (os.path.join(REF_DIR, "ê· ì—´_ëŒ€í‘œ.jpg"), "Concrete Crack"),
        (os.path.join(REF_DIR, "ë„ì¥ì†ìƒ_ëŒ€í‘œ.jpg"), "Paint Damage"),
        (os.path.join(REF_DIR, "ì² ê·¼ë…¸ì¶œ_ëŒ€í‘œ.jpg"), "Rebar Exposure")
    ]

    type_result = run_icl_llava(
        target_path,
        type_examples,
        "Select the type that is VISUALLY MOST SIMILAR to the examples.",
        "['Concrete Crack', 'Paint Damage', 'Rebar Exposure', 'None']",
        1
    )

    defect_type = "None"
    if "Crack" in type_result: defect_type = "Concrete Crack"
    elif "Paint" in type_result: defect_type = "Paint Damage"
    elif "Rebar" in type_result: defect_type = "Rebar Exposure"

    print(f"  1ì°¨ íŒì • ê²°ê³¼: {defect_type} (Raw: {type_result})")

    # ------step 2. ìœ„í—˜ë„ íŒë‹¨------
    """
    ê·œì¹™
    1. ë„ì¥ì†ìƒ -> í•˜ (w/o llava)
    2. ì² ê·¼ë…¸ì¶œ -> ìƒ (w/o llava)
    3. ë°•ë¦¬ -> ì¤‘/ìƒ (w/ llava)
    4. ê· ì—´ -> í•˜/ì¤‘/ìƒ (w/ llava)
    """
    print(">>> step 2: ìœ„í—˜ë„ ì¸¡ì • ì¤‘...")

    urgency = "Unknown"
    if defect_type=="None": urgency="None"
    elif defect_type=="Paint Damage": urgency="Low"
    elif defect_type=="Rebar Exposure": urgency="High"
    elif defect_type=="Concrete Crack":
        creck_examples = [
            (os.path.join(REF_DIR, "ê· ì—´_ìƒ.jpg"), "High"),
            (os.path.join(REF_DIR, "ê· ì—´_í•˜.jpg"), "Low"),
            (os.path.join(REF_DIR, "ê· ì—´_ì¤‘.jpg"), "Medium")
        ]

        urgency_result = run_icl_llava(
            target_path,
            creck_examples,
            "Based on the thickness and darkness of the crack compared to examples, what is the urgency?",
            "['Low', 'Medium', 'High']",
            0
        )
        if "High" in urgency_result: urgency = "High"
        elif "Medium" in urgency_result: urgency = "Medium"
        else: urgency = "Low" # ê¸°ë³¸ê°’
        print(f"***AI ê· ì—´ ìœ„í—˜ë„ íŒì •: {urgency} (Raw: {urgency_result})")

    defect_type_kr = defect_type_choice.get(defect_type, "ë¶„ë¥˜ ì•ˆë¨")

    urgency_kr = urgency_choice.get(urgency, "ë¶„ë¥˜ ì•ˆë¨")

    print("---- LLaVA ë‹µë³€(eng) ----")
    print(f"Defect type: {defect_type}, Urgency: {urgency}")
    print("---- LLaVA ë‹µë³€(kor) ----")
    print(f"ì†ìƒ ìœ í˜•: {defect_type_kr}, ìœ„í—˜ë„: {urgency_kr}")

    return defect_type_kr, urgency_kr
